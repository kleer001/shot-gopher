![ShotGopher Banner](https://i.imgur.com/VP9rmor.png)

![License](https://img.shields.io/github/license/kleer001/shot-gopher)
![Python](https://img.shields.io/badge/python-3.10+-blue)
![Platform](https://img.shields.io/badge/platform-Linux%20|%20macOS%20|%20Windows-lightgrey)
![GPU](https://img.shields.io/badge/GPU-NVIDIA%20CUDA-76B900?logo=nvidia)
![Tests](https://img.shields.io/github/actions/workflow/status/kleer001/shot-gopher/test.yml?label=tests)
![GitHub stars](https://img.shields.io/github/stars/kleer001/shot-gopher)
![GitHub forks](https://img.shields.io/github/forks/kleer001/shot-gopher)
![GitHub last commit](https://img.shields.io/github/last-commit/kleer001/shot-gopher)
![GitHub repo size](https://img.shields.io/github/repo-size/kleer001/shot-gopher)
![Contains Gophers](https://img.shields.io/badge/Contains-ğŸ¹%20Gophers-orange)
![Works on my machine](https://img.shields.io/badge/Works%20on-my%20machine-success)
![VFX Pipeline](https://img.shields.io/badge/ğŸ¬-VFX%20Pipeline-blue)
![WIP](https://img.shields.io/badge/Status-WIP%20ğŸš§-yellow)
![Badges](https://img.shields.io/badge/Badges-14-ff69b4)

Automated VFX Ingest pipeline. Start with footage, get first pass depth maps, roto, clean plates, camera solves, human matchmove, and 3D reconstructions. 

<details>
<summary><strong>Capabilities</strong></summary>

- **Frame extraction** - Convert video files to PNG frame sequences
- **Depth estimation** - Monocular depth maps with temporal consistency (Video Depth Anything)
- **Rotoscoping** - Text-prompted roto for dynamic object masking (SAM3)
- **Matte refinement** - Alpha matte generation for human subjects (VideoMaMa)
- **Clean plate generation** - Automated inpainting to remove objects from footage (ProPainter)
- **Camera tracking** - Structure-from-Motion camera solves with bundle adjustment (COLMAP)
- **3D reconstruction** - Dense point clouds and mesh generation from multi-view footage
- **Scene material decomposition** - Extract PBR material properties from multi-view footage via GS-IR (outputs EXR format)
  - Albedo maps (diffuse color without lighting)
  - Roughness maps (surface specularity)
  - Metallic maps (metallic vs dielectric)
  - Normal maps (surface orientation)
  - Environment lighting (HDR environment map)
- **Camera export** - Export to Alembic/JSON for Nuke, Maya, Houdini, Blender, After Effects
- **Human motion capture** - World-grounded skeleton tracking and mesh reconstruction (GVHMR)
- **Batch processing** - Automated multi-stage pipeline orchestration
- **Web interface** - Browser-based GUI for drag-and-drop operation

</details>

<details>
<summary><strong>Tools & Dependencies</strong></summary>

### Core Pipeline
- [ComfyUI](https://github.com/comfyanonymous/ComfyUI) - Node-based workflow engine for ML inference
- [Video Depth Anything](https://github.com/DepthAnything/Video-Depth-Anything) - Temporally consistent depth estimation
- [Segment Anything Model 2/3](https://github.com/facebookresearch/segment-anything-2) - Text-prompted rotoscoping
- [VideoMaMa](https://github.com/hywang66/VideoMaMa) - Video matting for human alpha mattes
- [ProPainter](https://github.com/sczhou/ProPainter) - Video inpainting for clean plates
- [COLMAP](https://colmap.github.io/) - Structure-from-Motion and Multi-View Stereo
- [FFmpeg](https://ffmpeg.org/) - Video/image processing

### Optional Components
- [Blender 4.2 LTS](https://www.blender.org/) - Mesh-to-Alembic export for camera/geometry data
- [GS-IR](https://github.com/lzhnb/GS-IR) - Gaussian Splatting for PBR material decomposition
- [GVHMR](https://github.com/zju3dv/GVHMR) - World-grounded human motion tracking (SIGGRAPH Asia 2024)
- [SMPL-X](https://smpl-x.is.tue.mpg.de/) - Parametric body model for motion capture

### ComfyUI Custom Nodes
- [ComfyUI-VideoHelperSuite](https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite) - Frame I/O handling
- [ComfyUI-DepthAnythingV3](https://github.com/PozzettiAndrea/ComfyUI-DepthAnythingV3) - Depth estimation node

### Python Dependencies
- PyTorch - Deep learning framework
- NumPy, OpenCV, Pillow - Image processing
- trimesh, smplx - 3D geometry (motion capture only)

</details>

---

### âš ï¸ğŸš§ Tool Limitations by Shot Type ğŸš§âš ï¸

> **ğŸ”¦ READ THIS BEFORE RUNNING THE PIPELINE ğŸ”¦**
>
> Different tools have different requirements. Not all footage works with all stages!

| Shot Type | Depth (VDA) | Roto (SAM3) | Interactive Roto | Matte (VideoMaMa) | Clean Plate | Camera (COLMAP) | Material (GS-IR) | MoCap (GVHMR) |
|-----------|-------------|-------------|------------------|-------------------|-------------|-----------------|------------------|---------------|
| **Static camera** | âœ… | âœ… | âœ… | âœ… | âœ… | ğŸš« | ğŸš« | âš ï¸ |
| **Moving camera** | âœ… | âœ… | âœ… | âœ… | âš ï¸ | âœ… | âœ… | âœ… |
| **Handheld/shaky** | âœ… | âš ï¸ | âš ï¸ | âš ï¸ | âš ï¸ | âš ï¸ | âš ï¸ | âš ï¸ |
| **Fast motion** | âš ï¸ | âš ï¸ | âš ï¸ | âš ï¸ | âš ï¸ | âš ï¸ | âš ï¸ | âš ï¸ |
| **Low texture** | âœ… | âœ… | âš ï¸ | âœ… | âœ… | ğŸš« | âš ï¸ | âœ… |
| **Full body person** | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | N/A | âœ… |
| **Partial body/occluded** | âœ… | âš ï¸ | âœ… | âš ï¸ | âš ï¸ | âœ… | N/A | âš ï¸ |
| **Multiple people** | âœ… | âš ï¸ | âœ… | âš ï¸ | âš ï¸ | âœ… | N/A | âœ… |
| **In-focus background** | âœ… | âœ… | âœ… | N/A | âœ… | âœ… | âœ… | N/A |
| **Shallow DOF/bokeh** | âš ï¸ | âœ… | âœ… | âœ… | âš ï¸ | âš ï¸ | âš ï¸ | âœ… |
| **High contrast lighting** | âœ… | âœ… | âœ… | âš ï¸ | âœ… | âœ… | âš ï¸ | âœ… |
| **150+ frames** | âœ… | âš ï¸ | âš ï¸ | âœ… | âœ… | âœ… | âš ï¸ | âš ï¸ |

ğŸ› ï¸ **Legend:**
- âœ… Works well
- âš ï¸ Limited/challenging â€” may require parameter tuning or produce imperfect results, excessive GPU RAM requirements 
- ğŸš« Not suitable/fails â€” tool requires different input (e.g., COLMAP needs camera motion)
- N/A Not applicable

ğŸ¦º **Key Gotchas:**
- **COLMAP** and **GS-IR** require camera movement â€” static tripod shots will fail
- **GVHMR** needs full or mostly-visible human bodies
- **VideoMaMa** is optimized for human subjects â€” uses chunked processing for long sequences
- **Interactive Roto** excels where auto-roto fails (occluded objects, separating similar items)
- **Long sequences (150+ frames)** may hit VRAM limits on 12GB cards

## Getting Started

### Linux / macOS

```bash
curl -fsSL https://raw.githubusercontent.com/kleer001/shot-gopher/main/scripts/bootstrap_conda.sh | bash
```

This script will:
- Clone the repository
- Set up a Conda environment
- Install all required dependencies
- Download ML models

**Prerequisites:** Git, Conda/Miniconda, NVIDIA GPU with driver (CUDA)

---

### Windows (PowerShell)

```powershell
irm https://raw.githubusercontent.com/kleer001/shot-gopher/main/scripts/bootstrap_conda.ps1 | iex
```

Run PowerShell as Administrator for best results.

**Prerequisites:** Git, Conda/Miniconda, NVIDIA GPU with driver (CUDA)

---

See [Manual Installation](docs/manual-install.md) for step-by-step setup or troubleshooting.



## Documentation

[First Project](docs/first-project.md) Â· [CLI Reference](docs/reference/cli.md) Â· [Pipeline Stages](docs/reference/stages.md) Â· [Troubleshooting](docs/troubleshooting.md)

<details>
<summary><strong>Project Structure</strong></summary>

Output follows VFX production conventions:
```
../vfx_projects/Shot_Name/
â”œâ”€â”€ source/frames/      # Input frames (frame_0001.png, ...)
â”œâ”€â”€ depth/              # Depth maps
â”œâ”€â”€ roto/               # Roto masks
â”‚   â”œâ”€â”€ mask/           # Combined mask
â”‚   â”œâ”€â”€ person_00/      # First person instance
â”‚   â””â”€â”€ person_01/      # Second person instance
â”œâ”€â”€ matte/              # Refined alpha mattes (person_00/, person_01/, etc.)
â”œâ”€â”€ cleanplate/         # Inpainted backgrounds
â”œâ”€â”€ camera/             # Camera data (Alembic, JSON, point clouds, meshes)
â””â”€â”€ colmap/             # COLMAP reconstruction data
```

**Note on frame numbering:** Frame sequences start at 0001 rather than the VFX industry standard of 1001. ComfyUI's SaveImage node output constraints make custom start frame numbering infeasible.

</details>

## Requirements

**Platform:** Linux, macOS, Windows | **Python:** 3.10+ | **GPU:** NVIDIA with CUDA (12GB+ VRAM recommended)

**Disk:** ~15 GB core, ~35 GB full install | **Dependencies:** Git, FFmpeg, Conda

<details>
<summary><strong>VRAM & Download Details</strong></summary>

| Component | VRAM | Download |
|-----------|------|----------|
| PyTorch + CUDA | â€” | 6.0 GB |
| ComfyUI + nodes | â€” | 2.5 GB |
| Video Depth Anything | ~7 GB | 1.5 GB |
| SAM3 (roto) | ~4 GB | 0.9 GB |
| ProPainter (clean plates) | ~6 GB | 0.5 GB |
| Blender 4.2 LTS | â€” | 0.5 GB |
| COLMAP (camera) | CPU | 0.2 GB |
| VideoMaMa (matte) | 12+ GB | 10.0 GB |
| GS-IR (materials) | 12+ GB | 2.0 GB |
| GVHMR (mocap) | 12+ GB | 4.0 GB |

**Motion capture** requires [SMPL-X registration](https://smpl-x.is.tue.mpg.de/) (free academic license, 24-48h approval).

</details>

## License

See [LICENSE](LICENSE) for details. This pipeline integrates multiple open-source projects with varying licenses - see [License Audit](docs/LICENSE_AUDIT_REPORT.md) for component details.
